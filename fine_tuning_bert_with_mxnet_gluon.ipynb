{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwon-n/cp2/blob/hyewon/fine_tuning_bert_with_mxnet_gluon.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ff6E-Vjaj-dd"
      },
      "source": [
        "I haven't seen a public kernel using Gluon NLP, so here is my simple example.  Adapted from https://gluon-nlp.mxnet.io/examples/sentence_embedding/bert.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6P86vJeHkfWv",
        "outputId": "a19d7111-94e9-43df-bfd1-ebdab146b237"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gluonnlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uei3tmi-kFSH",
        "outputId": "5112c513-d909-40ef-c02e-3893605edf4e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gluonnlp\n",
            "  Downloading gluonnlp-0.10.0.tar.gz (344 kB)\n",
            "\u001b[?25l\r\u001b[K     |█                               | 10 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 20 kB 25.4 MB/s eta 0:00:01\r\u001b[K     |██▉                             | 30 kB 12.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 40 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 51 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 61 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 71 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 81 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 344 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.21.5)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.28)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (3.0.7)\n",
            "Building wheels for collected packages: gluonnlp\n",
            "  Building wheel for gluonnlp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gluonnlp: filename=gluonnlp-0.10.0-cp37-cp37m-linux_x86_64.whl size=595757 sha256=b24c196ab1b92fa48b715abd57d3addc6b229bd834c1c2960f9272821076eba2\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/b4/06/7f3fdfaf707e6b5e98b79c041e023acffbe395d78a527eae00\n",
            "Successfully built gluonnlp\n",
            "Installing collected packages: gluonnlp\n",
            "Successfully installed gluonnlp-0.10.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/google/colab/_pip.py:87: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.7/dist-packages/gluonnlp-0.10.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mxnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N4t3JAjZkApC",
        "outputId": "af261e81-94fd-4549-d6a9-af63dbbbb749"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mxnet\n",
            "  Downloading mxnet-1.9.0-py3-none-manylinux2014_x86_64.whl (47.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.3 MB 73 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.21.5)\n",
            "Collecting graphviz<0.9.0,>=0.8.1\n",
            "  Downloading graphviz-0.8.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
            "Installing collected packages: graphviz, mxnet\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.10.1\n",
            "    Uninstalling graphviz-0.10.1:\n",
            "      Successfully uninstalled graphviz-0.10.1\n",
            "Successfully installed graphviz-0.8.4 mxnet-1.9.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/google/colab/_pip.py:87: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.7/dist-packages/graphviz-0.8.4.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n",
            "/usr/local/lib/python3.7/dist-packages/google/colab/_pip.py:87: ResourceWarning: unclosed file <_io.TextIOWrapper name='/usr/local/lib/python3.7/dist-packages/mxnet-1.9.0.dist-info/top_level.txt' mode='r' encoding='UTF-8'>\n",
            "  for line in open(toplevel):\n",
            "ResourceWarning: Enable tracemalloc to get the object allocation traceback\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Z2Oesm8kj-dk"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(action='once')\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "import random\n",
        "import multiprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm_notebook, tqdm\n",
        "\n",
        "import mxnet as mx\n",
        "from mxnet import gluon\n",
        "from mxnet.gluon import Block\n",
        "from mxnet.gluon import nn\n",
        "import gluonnlp as nlp\n",
        "from gluonnlp.data import BERTTokenizer, BERTSentenceTransform"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "VGDnJxHZj-dp"
      },
      "outputs": [],
      "source": [
        "train_tsv = '/content/drive/MyDrive/news_class9x13000/train.tsv'\n",
        "test_tsv = '/content/drive/MyDrive/news_class9x13000/test.tsv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "DKcoQO0tj-dq"
      },
      "outputs": [],
      "source": [
        "test_size=15000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "BHccPxtPj-dq",
        "outputId": "fd510c3c-a344-4f8c-8fbd-c1d1619722af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   isNext                                             prompt  \\\n",
              "0       1                  프로크루스테스의 침대라는 그리스신화에 나오는 이야기가 있다.   \n",
              "1       0  이 이야기는 프로크루스테스라는 사람이 지나가는 나그네를 자신의 집으로 잡아와서 침대...   \n",
              "2       0                               결국 침대에 사람을 맞춘다는 얘기다.   \n",
              "3       0       올해부터 실시하고 있는 활동보조서비스 개악 지침도 이것과 다르지 않게 잔인하다.   \n",
              "4       1  장애인활동보조서비스는 장애로 인해 일상생활의 어려움을 겪는 사람들의 원활한 일상생활...   \n",
              "\n",
              "                                                next  \n",
              "0  이 이야기는 프로크루스테스라는 사람이 지나가는 나그네를 자신의 집으로 잡아와서 침대...  \n",
              "1  또, 안전행정부와 기획재정부는 전 부처와 공공기관을 대상으로 여름휴가 하루 더 가기...  \n",
              "2       올해부터 실시하고 있는 활동보조서비스 개악 지침도 이것과 다르지 않게 잔인하다.  \n",
              "3  흥선대원군은 이홍장의 심문을 받은 후 바오딩(保定)으로 옮겨져 4년간 중국에서 불우...  \n",
              "4  2007년부터 시작한 이 서비스 제도는 전국의 중증장애인들이 국가를 상대로 치열한 ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-18b7d5e8-3753-4fd9-90de-506c8e03dc02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isNext</th>\n",
              "      <th>prompt</th>\n",
              "      <th>next</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>프로크루스테스의 침대라는 그리스신화에 나오는 이야기가 있다.</td>\n",
              "      <td>이 이야기는 프로크루스테스라는 사람이 지나가는 나그네를 자신의 집으로 잡아와서 침대...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>이 이야기는 프로크루스테스라는 사람이 지나가는 나그네를 자신의 집으로 잡아와서 침대...</td>\n",
              "      <td>또, 안전행정부와 기획재정부는 전 부처와 공공기관을 대상으로 여름휴가 하루 더 가기...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>결국 침대에 사람을 맞춘다는 얘기다.</td>\n",
              "      <td>올해부터 실시하고 있는 활동보조서비스 개악 지침도 이것과 다르지 않게 잔인하다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>올해부터 실시하고 있는 활동보조서비스 개악 지침도 이것과 다르지 않게 잔인하다.</td>\n",
              "      <td>흥선대원군은 이홍장의 심문을 받은 후 바오딩(保定)으로 옮겨져 4년간 중국에서 불우...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>장애인활동보조서비스는 장애로 인해 일상생활의 어려움을 겪는 사람들의 원활한 일상생활...</td>\n",
              "      <td>2007년부터 시작한 이 서비스 제도는 전국의 중증장애인들이 국가를 상대로 치열한 ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-18b7d5e8-3753-4fd9-90de-506c8e03dc02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-18b7d5e8-3753-4fd9-90de-506c8e03dc02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-18b7d5e8-3753-4fd9-90de-506c8e03dc02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "train_df = pd.read_csv(train_tsv, delimiter = '\\t', header = None)\n",
        "train_df.columns = ['isNext', 'prompt', 'next']\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "tNzgHKihj-dr",
        "outputId": "ae879f38-b2cb-4aac-e273-5c97b24261b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   isNext                       prompt  \\\n",
              "0       1              보름달 뜨면 구름 자주 끼고   \n",
              "1       0           꽃이 활짝 피면 바람이 불어대지.   \n",
              "2       1              세상일이란 모두 이런 거야.   \n",
              "3       0         나 홀로 웃는 까닭 아는 이 없을걸.   \n",
              "4       1  정약용이 지은 독소(獨笑·홀로 웃다)라는 시이다.   \n",
              "\n",
              "                                        next  \n",
              "0                         꽃이 활짝 피면 바람이 불어대지.  \n",
              "1                   ◈ 안쓰고 쌓아두면 세금...기업소득환류세제  \n",
              "2                       나 홀로 웃는 까닭 아는 이 없을걸.  \n",
              "3                  권력기관에서 경력을 쌓은 인물들도 적지 않다.  \n",
              "4  이렇게 인간사 누구나 한 가지씩 걱정거리를 안고 사는 게 우리네 인생이다.  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-144c30bd-6280-461b-997a-01b6c41e907c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isNext</th>\n",
              "      <th>prompt</th>\n",
              "      <th>next</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>보름달 뜨면 구름 자주 끼고</td>\n",
              "      <td>꽃이 활짝 피면 바람이 불어대지.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>꽃이 활짝 피면 바람이 불어대지.</td>\n",
              "      <td>◈ 안쓰고 쌓아두면 세금...기업소득환류세제</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>세상일이란 모두 이런 거야.</td>\n",
              "      <td>나 홀로 웃는 까닭 아는 이 없을걸.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>나 홀로 웃는 까닭 아는 이 없을걸.</td>\n",
              "      <td>권력기관에서 경력을 쌓은 인물들도 적지 않다.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>정약용이 지은 독소(獨笑·홀로 웃다)라는 시이다.</td>\n",
              "      <td>이렇게 인간사 누구나 한 가지씩 걱정거리를 안고 사는 게 우리네 인생이다.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-144c30bd-6280-461b-997a-01b6c41e907c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-144c30bd-6280-461b-997a-01b6c41e907c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-144c30bd-6280-461b-997a-01b6c41e907c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "test_df = pd.read_csv(test_tsv, delimiter = '\\t', header = None)\n",
        "test_df.columns = ['isNext', 'prompt', 'next']\n",
        "test_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9eirT46j-ds",
        "outputId": "3d9aed24-fa39-4e26-e0f2-2d25fffcec20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7000000</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7000001</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7000002</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7000003</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7000004</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  prediction\n",
              "0  7000000         0.0\n",
              "1  7000001         0.0\n",
              "2  7000002         0.0\n",
              "3  7000003         0.0\n",
              "4  7000004         0.0"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sample_df = pd.read_csv(sample_csv)\n",
        "sample_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_M1BF3u_j-dt"
      },
      "source": [
        "### classes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "o-UjGJxBj-du"
      },
      "outputs": [],
      "source": [
        "class BERTClassifier(Block):\n",
        "    \"\"\"Model for sentence (pair) classification task with BERT.\n",
        "\n",
        "    The model feeds token ids and token type ids into BERT to get the\n",
        "    pooled BERT sequence representation, then apply a Dense layer for\n",
        "    classification.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    bert: BERTModel\n",
        "        Bidirectional encoder with transformer.\n",
        "    num_classes : int, default is 2\n",
        "        The number of target classes.\n",
        "    dropout : float or None, default 0.0.\n",
        "        Dropout probability for the bert output.\n",
        "    prefix : str or None\n",
        "        See document of `mx.gluon.Block`.\n",
        "    params : ParameterDict or None\n",
        "        See document of `mx.gluon.Block`.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 bert,\n",
        "                 num_classes=2,\n",
        "                 dropout=0.0,\n",
        "                 prefix=None,\n",
        "                 params=None):\n",
        "        super(BERTClassifier, self).__init__(prefix=prefix, params=params)\n",
        "        self.bert = bert\n",
        "        with self.name_scope():\n",
        "            self.classifier = nn.HybridSequential(prefix=prefix)\n",
        "            if dropout:\n",
        "                self.classifier.add(nn.Dropout(rate=dropout))\n",
        "            self.classifier.add(nn.Dense(units=num_classes))\n",
        "\n",
        "    def forward(self, inputs, token_types, valid_length=None):  # pylint: disable=arguments-differ\n",
        "        \"\"\"Generate the unnormalized score for the given the input sequences.\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        inputs : NDArray, shape (batch_size, seq_length)\n",
        "            Input words for the sequences.\n",
        "        token_types : NDArray, shape (batch_size, seq_length)\n",
        "            Token types for the sequences, used to indicate whether the word belongs to the\n",
        "            first sentence or the second one.\n",
        "        valid_length : NDArray or None, shape (batch_size)\n",
        "            Valid length of the sequence. This is used to mask the padded tokens.\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        outputs : NDArray\n",
        "            Shape (batch_size, num_classes)\n",
        "        \"\"\"\n",
        "        _, pooler_out = self.bert(inputs, token_types, valid_length)\n",
        "        return self.classifier(pooler_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7jI96t59j-dv"
      },
      "outputs": [],
      "source": [
        "class BERTDatasetTransform(object):\n",
        "    \"\"\"Dataset Transformation for BERT-style Sentence Classification or Regression.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    tokenizer : BERTTokenizer.\n",
        "        Tokenizer for the sentences.\n",
        "    max_seq_length : int.\n",
        "        Maximum sequence length of the sentences.\n",
        "    labels : list of int , float or None. defaults None\n",
        "        List of all label ids for the classification task and regressing task.\n",
        "        If labels is None, the default task is regression\n",
        "    pad : bool, default True\n",
        "        Whether to pad the sentences to maximum length.\n",
        "    pair : bool, default True\n",
        "        Whether to transform sentences or sentence pairs.\n",
        "    label_dtype: int32 or float32, default float32\n",
        "        label_dtype = int32 for classification task\n",
        "        label_dtype = float32 for regression task\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 tokenizer,\n",
        "                 max_seq_length,\n",
        "                 class_labels=None,\n",
        "                 pad=True,\n",
        "                 pair=True,\n",
        "                 has_label=True):\n",
        "        self.class_labels = class_labels\n",
        "        self.has_label = has_label\n",
        "        self._label_dtype = 'int32' if class_labels else 'float32'\n",
        "        if has_label and class_labels:\n",
        "            self._label_map = {}\n",
        "            for (i, label) in enumerate(class_labels):\n",
        "                self._label_map[label] = i\n",
        "        self._bert_xform = BERTSentenceTransform(\n",
        "            tokenizer, max_seq_length, pad=pad, pair=pair)\n",
        "\n",
        "    def __call__(self, line):\n",
        "        \"\"\"Perform transformation for sequence pairs or single sequences.\n",
        "\n",
        "        The transformation is processed in the following steps:\n",
        "        - tokenize the input sequences\n",
        "        - insert [CLS], [SEP] as necessary\n",
        "        - generate type ids to indicate whether a token belongs to the first\n",
        "          sequence or the second sequence.\n",
        "        - generate valid length\n",
        "\n",
        "        For sequence pairs, the input is a tuple of 3 strings:\n",
        "        text_a, text_b and label.\n",
        "\n",
        "        Inputs:\n",
        "            text_a: 'is this jacksonville ?'\n",
        "            text_b: 'no it is not'\n",
        "            label: '0'\n",
        "        Tokenization:\n",
        "            text_a: 'is this jack ##son ##ville ?'\n",
        "            text_b: 'no it is not .'\n",
        "        Processed:\n",
        "            tokens:  '[CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]'\n",
        "            type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "            valid_length: 14\n",
        "            label: 0\n",
        "\n",
        "        For single sequences, the input is a tuple of 2 strings: text_a and label.\n",
        "        Inputs:\n",
        "            text_a: 'the dog is hairy .'\n",
        "            label: '1'\n",
        "        Tokenization:\n",
        "            text_a: 'the dog is hairy .'\n",
        "        Processed:\n",
        "            text_a:  '[CLS] the dog is hairy . [SEP]'\n",
        "            type_ids: 0     0   0   0  0     0 0\n",
        "            valid_length: 7\n",
        "            label: 1\n",
        "\n",
        "        Parameters\n",
        "        ----------\n",
        "        line: tuple of str\n",
        "            Input strings. For sequence pairs, the input is a tuple of 3 strings:\n",
        "            (text_a, text_b, label). For single sequences, the input is a tuple\n",
        "            of 2 strings: (text_a, label).\n",
        "\n",
        "        Returns\n",
        "        -------\n",
        "        np.array: input token ids in 'int32', shape (batch_size, seq_length)\n",
        "        np.array: valid length in 'int32', shape (batch_size,)\n",
        "        np.array: input token type ids in 'int32', shape (batch_size, seq_length)\n",
        "        np.array: classification task: label id in 'int32', shape (batch_size, 1),\n",
        "            regression task: label in 'float32', shape (batch_size, 1)\n",
        "        \"\"\"\n",
        "        if self.has_label:\n",
        "            input_ids, valid_length, segment_ids = self._bert_xform(line[:-1])\n",
        "            label = line[-1]\n",
        "            # map to int if class labels are available\n",
        "            if self.class_labels:\n",
        "                label = self._label_map[label]\n",
        "            label = np.array([label], dtype=self._label_dtype)\n",
        "            return input_ids, valid_length, segment_ids, label\n",
        "        else:\n",
        "            return self._bert_xform(line)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0PqxVS8Rj-dx"
      },
      "source": [
        "### preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "bZQIJY2vj-dx"
      },
      "outputs": [],
      "source": [
        "ctx = mx.cpu()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "njLRPucuj-dy"
      },
      "outputs": [],
      "source": [
        "max_len = 128\n",
        "pad = True\n",
        "pair = True\n",
        "\n",
        "epochs = 1\n",
        "batch_size = 32\n",
        "#optimizer='bertadam'\n",
        "class_labels=[0,1]\n",
        "lr = 1e-6\n",
        "epsilon = 1e-06\n",
        "warmup_ratio = 0.1\n",
        "log_interval = 1000\n",
        "accumulate = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4kouIH-zj-dy",
        "outputId": "81307526-7884-4311-b514-8646e6a1b81d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocab file is not found. Downloading.\n",
            "Downloading /content/drive/MyDrive/bert-mx/6865855176093913707/6865855176093913707_wiki_multilingual_cased-0247cb44.zip from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/dataset/vocab/wiki_multilingual_cased-0247cb44.zip...\n",
            "Downloading /content/drive/MyDrive/bert-mx/bert_12_768_12_wiki_multilingual_cased-b0f57a20.zipb85694ca-2b90-40c8-b7b5-871168057249 from https://apache-mxnet.s3-accelerate.dualstack.amazonaws.com/gluon/models/bert_12_768_12_wiki_multilingual_cased-b0f57a20.zip...\n"
          ]
        }
      ],
      "source": [
        "bert_base, vocabulary = nlp.model.get_model('bert_12_768_12', \n",
        "                                             dataset_name='wiki_multilingual_cased',\n",
        "                                             pretrained=True, ctx=ctx, use_pooler=True,\n",
        "                                             use_decoder=False, use_classifier=False,\n",
        "                                             root='/content/drive/MyDrive/bert-mx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "Qbm9ijQLj-dz"
      },
      "outputs": [],
      "source": [
        "model = BERTClassifier(bert_base, num_classes=2, dropout=0.1)\n",
        "# only need to initialize the classifier layer.\n",
        "model.classifier.initialize(init=mx.init.Normal(0.02), ctx=ctx)\n",
        "model.hybridize(static_alloc=True)\n",
        "\n",
        "# softmax cross entropy loss for classification\n",
        "loss_function = gluon.loss.SoftmaxCELoss()\n",
        "loss_function.hybridize(static_alloc=True)\n",
        "\n",
        "metric = mx.metric.Accuracy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vPPde7qvj-dz"
      },
      "outputs": [],
      "source": [
        "tokenizer = nlp.data.BERTTokenizer(vocabulary, lower=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dTIEN5K-j-d0"
      },
      "outputs": [],
      "source": [
        "train_df['prompt'] = train_df['prompt'].astype(str)\n",
        "train_df['next'] = train_df['next'].astype(str)\n",
        "train_df['isNext']=train_df['isNext'].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "AzM6inNXj-d0"
      },
      "outputs": [],
      "source": [
        "train_data_raw = train_df[['prompt', 'next', 'isNext']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWEG1TJAj-d0",
        "outputId": "d768e26c-530f-473d-c5ce-3a8534f5916d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gluonnlp/data/batchify/batchify.py:235: UserWarning: Padding value is not given and will be set automatically to 0 in data.batchify.Pad(). Please check whether this is intended (e.g. value of padding index in the vocabulary).\n",
            "  'Padding value is not given and will be set automatically to 0 '\n"
          ]
        }
      ],
      "source": [
        "pool = multiprocessing.Pool()\n",
        "\n",
        "# transformation for data train and dev\n",
        "#label_dtype = 'float32' if not task.class_labels else 'int32'\n",
        "label_dtype='int32'\n",
        "trans = BERTDatasetTransform(tokenizer, max_len,\n",
        "                             class_labels=class_labels,\n",
        "                             pad=pad, pair=pair,\n",
        "                             has_label=True)\n",
        "\n",
        "# data train\n",
        "# task.dataset_train returns (segment_name, dataset)\n",
        "#train_tsv = task.dataset_train()[1]\n",
        "#data_train = mx.gluon.data.SimpleDataset(pool.map(trans, train_data_raw))\n",
        "data_train = mx.gluon.data.SimpleDataset(train_data_raw)\n",
        "data_train = data_train.transform(trans)\n",
        "data_train_len = data_train.transform(\n",
        "    lambda input_id, length, segment_id, label_id: length, lazy=False)\n",
        "# bucket sampler for training\n",
        "batchify_fn = nlp.data.batchify.Tuple(\n",
        "    nlp.data.batchify.Pad(axis=0), nlp.data.batchify.Stack(),\n",
        "    nlp.data.batchify.Pad(axis=0), nlp.data.batchify.Stack(label_dtype))\n",
        "batch_sampler = nlp.data.sampler.FixedBucketSampler(\n",
        "    data_train_len,\n",
        "    batch_size=batch_size,\n",
        "    #num_buckets=10,\n",
        "    ratio=0,\n",
        "    shuffle=True)\n",
        "# data loader for training\n",
        "train_data = gluon.data.DataLoader(\n",
        "    dataset=data_train,\n",
        "    num_workers=4,\n",
        "    batch_sampler=batch_sampler,\n",
        "    batchify_fn=batchify_fn)\n",
        "num_train_examples = len(data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6p-9PWjj-d1",
        "outputId": "ac36ff39-0fed-41ba-d86b-1fc3d52b808c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "vocabulary used for tokenization = \n",
            "Vocab(size=119547, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n",
            "[PAD] token id = 1\n",
            "[CLS] token id = 2\n",
            "[SEP] token id = 3\n",
            "token ids = \n",
            "[  2   0   0   0   0   0   0   0   0   0   0   0   0   0 119   3   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0 119   3   1   1   1   1\n",
            "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
            "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
            "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
            "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
            "   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1\n",
            "   1   1]\n",
            "valid length = \n",
            "32\n",
            "segment ids = \n",
            "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "label = \n",
            "[1]\n"
          ]
        }
      ],
      "source": [
        "print('vocabulary used for tokenization = \\n%s'%vocabulary)\n",
        "print('[PAD] token id = %s'%(vocabulary['[PAD]']))\n",
        "print('[CLS] token id = %s'%(vocabulary['[CLS]']))\n",
        "print('[SEP] token id = %s'%(vocabulary['[SEP]']))\n",
        "print('token ids = \\n%s'%data_train[4][0])\n",
        "print('valid length = \\n%s'%data_train[4][1])\n",
        "print('segment ids = \\n%s'%data_train[4][2])\n",
        "print('label = \\n%s'%data_train[4][3])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KObIxzsj-d2"
      },
      "source": [
        "### training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "NFEC43L3j-d2"
      },
      "outputs": [],
      "source": [
        "optimizer = mx.optimizer.create('adam', multi_precision=True, learning_rate=lr, epsilon=epsilon)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "FpWoUn4Tj-d3"
      },
      "outputs": [],
      "source": [
        "all_model_params = model.collect_params()\n",
        "optimizer_params = {'learning_rate': lr, 'epsilon': epsilon, 'wd': 0.01}\n",
        "\n",
        "try:\n",
        "    trainer = gluon.Trainer(all_model_params, optimizer,\n",
        "                            update_on_kvstore=False)\n",
        "except ValueError as e:\n",
        "    print(e)\n",
        "    warnings.warn(\n",
        "        'AdamW optimizer is not found. Please consider upgrading to '\n",
        "        'mxnet>=1.5.0. Now the original Adam optimizer is used instead.')\n",
        "    trainer = gluon.Trainer(all_model_params, 'adam',\n",
        "                            optimizer_params, update_on_kvstore=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pb72-Xxrj-d5"
      },
      "outputs": [],
      "source": [
        "step_size = batch_size * accumulate if accumulate else batch_size\n",
        "num_train_steps = int(num_train_examples / step_size * epochs)\n",
        "num_warmup_steps = int(num_train_steps * warmup_ratio)\n",
        "step_num = 0\n",
        "\n",
        "# Do not apply weight decay on LayerNorm and bias terms\n",
        "for _, v in model.collect_params('.*beta|.*gamma|.*bias').items():\n",
        "    v.wd_mult = 0.0\n",
        "# Collect differentiable parameters\n",
        "params = [p for p in all_model_params.values() if p.grad_req != 'null']\n",
        "\n",
        "# Set grad_req if gradient accumulation is required\n",
        "if accumulate:\n",
        "    for p in params:\n",
        "        p.grad_req = 'add'\n",
        "\n",
        "#tic = time.time()\n",
        "for epoch_id in range(epochs):\n",
        "    metric.reset()\n",
        "    step_loss = 0\n",
        "    #tic = time.time()\n",
        "    all_model_params.zero_grad()\n",
        "\n",
        "    for batch_id, seqs in enumerate(train_data):\n",
        "        # learning rate schedule\n",
        "        if step_num < num_warmup_steps:\n",
        "            new_lr = lr * step_num / num_warmup_steps\n",
        "        else:\n",
        "            non_warmup_steps = step_num - num_warmup_steps\n",
        "            offset = non_warmup_steps / (num_train_steps - num_warmup_steps)\n",
        "            new_lr = lr - offset * lr\n",
        "        optimizer.set_learning_rate(new_lr)\n",
        "\n",
        "        # forward and backward\n",
        "        with mx.autograd.record():\n",
        "            input_ids, valid_length, type_ids, label = seqs\n",
        "            out = model(\n",
        "                input_ids.as_in_context(ctx), type_ids.as_in_context(ctx),\n",
        "                valid_length.astype('float32').as_in_context(ctx))\n",
        "            ls = loss_function(out, label.as_in_context(ctx)).mean()\n",
        "        ls.backward()\n",
        "\n",
        "        # update\n",
        "        if not accumulate or (batch_id + 1) % accumulate == 0:\n",
        "            trainer.allreduce_grads()\n",
        "            nlp.utils.clip_grad_global_norm(params, 1)\n",
        "            trainer.update(accumulate if accumulate else 1)\n",
        "            # set grad to zero for gradient accumulation\n",
        "            all_model_params.zero_grad()\n",
        "            step_num += 1\n",
        "\n",
        "        step_loss += ls.asscalar()\n",
        "        metric.update([label], [out])\n",
        "        if (batch_id + 1) % (log_interval) == 0:\n",
        "            #log_train(batch_id, len(train_data), metric, step_loss, log_interval,\n",
        "                      #epoch_id, trainer.learning_rate)\n",
        "            print('[Epoch {} Batch {}/{}] loss={:.4f}, lr={:.7f}, acc={:.3f}'\n",
        "                  .format(epoch_id, batch_id + 1, len(train_data),\n",
        "                 step_loss / log_interval,\n",
        "                 optimizer.learning_rate, metric.get()[1]))\n",
        "            step_loss = 0\n",
        "    mx.nd.waitall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGgSJRsoj-d6"
      },
      "outputs": [],
      "source": [
        "model.save_parameters('j-20190616k')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "XUNlxxNqj-d7"
      },
      "source": [
        "### prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ud1UYCNij-d7"
      },
      "outputs": [],
      "source": [
        "test_df['comment_text'] = test_df['comment_text'].astype(str)\n",
        "test_data_raw = test_df[['comment_text']].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mAfDj8fbj-d7"
      },
      "outputs": [],
      "source": [
        "# batchify for data test\n",
        "test_batchify_fn = nlp.data.batchify.Tuple(\n",
        "    nlp.data.batchify.Pad(axis=0), nlp.data.batchify.Stack(),\n",
        "    nlp.data.batchify.Pad(axis=0))\n",
        "\n",
        "# transform for data test\n",
        "test_trans = BERTDatasetTransform(tokenizer, max_len,\n",
        "                                  class_labels=None,\n",
        "                                  pad=pad, pair=pair,\n",
        "                                  has_label=False)\n",
        "\n",
        "data_test = mx.gluon.data.SimpleDataset(pool.map(test_trans, test_data_raw))\n",
        "loader_test = mx.gluon.data.DataLoader(\n",
        "    data_test,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4,\n",
        "    shuffle=False,\n",
        "    batchify_fn=test_batchify_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgMCF1Tdj-d7",
        "outputId": "525ee4f8-23ad-4f0c-9bed-c8d108f50078"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([   2, 5076, 6521, 2003, 2178, 2028, 1997, 8398, 1005, 1055, 2030,\n",
              "        4381, 2937, 9804, 1012, 2002, 7164, 1998, 2038, 3373, 2010, 2972,\n",
              "        2476, 1996, 6635, 4500, 1997, 2054, 1996, 2597, 5942, 1012,    3,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
              "           1,    1,    1,    1,    1,    1,    1], dtype=int32),\n",
              " array(33, dtype=int32),\n",
              " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32))"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_test[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81Te531tj-d8"
      },
      "outputs": [],
      "source": [
        "#value_list = []\n",
        "#index_list = []\n",
        "results = []\n",
        "for _, seqs in enumerate(loader_test):\n",
        "    input_ids, valid_length, type_ids = seqs\n",
        "    out = model(input_ids.as_in_context(ctx),\n",
        "                type_ids.as_in_context(ctx),\n",
        "                valid_length.astype('float32').as_in_context(ctx))\n",
        "    results.extend([o for o in out.asnumpy()])\n",
        "    #values, indices = mx.nd.topk(out, k=1, ret_typ='both')\n",
        "    #value_list.extend(values.asnumpy().reshape(-1).tolist())\n",
        "    #index_list.extend(indices.asnumpy().reshape(-1).tolist())\n",
        "\n",
        "mx.nd.waitall()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STUsbiDCj-d8",
        "outputId": "7257ca0e-f5c2-4e92-ea89-3108052bd61f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([-1.2963991,  1.0346556], dtype=float32)"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "results[24]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9lEZ5SYj-d8"
      },
      "outputs": [],
      "source": [
        "predictions = [mx.nd.array(result).softmax().asnumpy()[1] for result in results]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzXSStb4j-d8"
      },
      "outputs": [],
      "source": [
        "submission = pd.DataFrame.from_dict({\n",
        "    'id': test_df['id'],\n",
        "    'prediction': predictions\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DqH_tDkUj-d9"
      },
      "outputs": [],
      "source": [
        "submission.to_csv('submission.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "name": "fine-tuning-bert-with-mxnet-gluon.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}