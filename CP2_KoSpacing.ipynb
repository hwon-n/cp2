{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hwon-n/cp2/blob/hyewon/CP2_KoSpacing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J2kElC3mkwU"
      },
      "source": [
        "# 띄어쓰기 검사 모델 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bEqSiuM1m3a5"
      },
      "source": [
        "## 필요한 패키지 다운로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G2taSuFyo27r",
        "outputId": "fcd852b7-aa17-476a-c987-0ba6952277ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuOqE2rFCdh5",
        "outputId": "382406d7-c6c6-415e-9cbb-0e22659ffa62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kss\n",
            "  Downloading kss-3.4.tar.gz (42.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 42.4 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting emoji\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[K     |████████████████████████████████| 175 kB 36.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2019.12.20)\n",
            "Building wheels for collected packages: kss, emoji\n",
            "  Building wheel for kss (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for kss: filename=kss-3.4-py3-none-any.whl size=42449209 sha256=12065e97faefe66de4c9450807cc3460e53768bf120f7439d68531a6601f03e6\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/8e/5b/305f0a804fba3943f353f1b0e3cb1fad39e4f5ae4893ea9590\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171046 sha256=b07f7e2dde74c6b1450ed3e08de7f51bde547319757ad66b12c680f987072297\n",
            "  Stored in directory: /root/.cache/pip/wheels/8a/4e/b6/57b01db010d17ef6ea9b40300af725ef3e210cb1acfb7ac8b6\n",
            "Successfully built kss emoji\n",
            "Installing collected packages: emoji, kss\n",
            "Successfully installed emoji-1.7.0 kss-3.4\n"
          ]
        }
      ],
      "source": [
        "!pip install kss"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentencepiece"
      ],
      "metadata": {
        "id": "YLazE4sBCrtt",
        "outputId": "777fefe5-422d-4176-a40b-7a993fbdc9eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 21.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 51 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 61 kB 7.3 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 8.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 81 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 92 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 102 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 112 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 122 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 133 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 143 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 153 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 163 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 174 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 184 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 194 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 204 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 215 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 225 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 235 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 245 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 256 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 266 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 276 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 286 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 296 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 307 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 317 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 327 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 337 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 348 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 358 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 368 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 378 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 389 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 399 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 409 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 419 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 430 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 440 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 450 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 460 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 471 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 481 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 491 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 501 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 512 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 522 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 532 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 542 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 552 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 563 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 573 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 583 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 593 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 604 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 614 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 624 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 634 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 645 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 655 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 665 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 675 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 686 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 696 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 706 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 716 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 727 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 737 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 747 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 757 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 768 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 778 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 788 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 798 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 808 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 819 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 829 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 839 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 849 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 860 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 870 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 880 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 890 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 901 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 911 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 921 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▋       | 931 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 942 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 952 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 962 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 972 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 983 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 993 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.0 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.0 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.0 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.0 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.0 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 1.2 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.2 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.2 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 1.2 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.2 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.2 MB 7.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.2 MB 7.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install utils"
      ],
      "metadata": {
        "id": "tfNUMl6LBqqn",
        "outputId": "02637af1-4e99-40c1-c909-87107d272825",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting utils\n",
            "  Downloading utils-1.0.1-py2.py3-none-any.whl (21 kB)\n",
            "Installing collected packages: utils\n",
            "Successfully installed utils-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pytorch_lightning"
      ],
      "metadata": {
        "id": "7rdIrujABpKP",
        "outputId": "e4c05486-6ea2-4d2d-8644-e076b8995b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pytorch_lightning in /usr/local/lib/python3.7/dist-packages (1.5.10)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.21.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (6.0)\n",
            "Requirement already satisfied: torch>=1.7.* in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (1.10.0+cu111)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.3.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (3.10.0.2)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2.8.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (4.63.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (21.3)\n",
            "Requirement already satisfied: setuptools==59.5.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (59.5.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.18.2)\n",
            "Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (2022.2.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning) (0.7.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.23.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=17.0->pytorch_lightning) (3.0.7)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.44.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.4.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (3.3.6)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.0.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (0.6.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard>=2.2.0->pytorch_lightning) (1.35.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard>=2.2.0->pytorch_lightning) (1.15.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (4.11.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard>=2.2.0->pytorch_lightning) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.2.0->pytorch_lightning) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (3.0.4)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch_lightning) (3.2.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.3.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (1.7.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (0.13.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch_lightning) (21.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install omegaconf"
      ],
      "metadata": {
        "id": "VsO5KP9qBk45",
        "outputId": "bfedc12b-0fd6-43ce-dd24-31809096aea7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting omegaconf\n",
            "  Downloading omegaconf-2.1.1-py3-none-any.whl (74 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▍                           | 10 kB 9.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 20 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 30 kB 15.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 40 kB 7.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 51 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 61 kB 9.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 71 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 74 kB 2.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.1.0 in /usr/local/lib/python3.7/dist-packages (from omegaconf) (6.0)\n",
            "Collecting antlr4-python3-runtime==4.8\n",
            "  Downloading antlr4-python3-runtime-4.8.tar.gz (112 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 48.6 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 20 kB 54.2 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 30 kB 61.5 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 40 kB 62.3 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 51 kB 64.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 61 kB 68.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 71 kB 60.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 81 kB 61.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 92 kB 63.9 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 102 kB 19.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112 kB 19.4 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-py3-none-any.whl size=141230 sha256=1531a2befe31e35d4a4dc38a168484b667ced333e8f5c78efdee406471a2611f\n",
            "  Stored in directory: /root/.cache/pip/wheels/ca/33/b7/336836125fc9bb4ceaa4376d8abca10ca8bc84ddc824baea6c\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: antlr4-python3-runtime, omegaconf\n",
            "Successfully installed antlr4-python3-runtime-4.8 omegaconf-2.1.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install seqeval"
      ],
      "metadata": {
        "id": "CiSH4mg2bYyd",
        "outputId": "3c1b74e8-7ec0-4340-a43a-a3b8d9d47159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting seqeval\n",
            "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
            "\u001b[?25l\r\u001b[K     |███████▌                        | 10 kB 26.1 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 20 kB 29.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 30 kB 15.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 40 kB 11.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 43 kB 1.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a71e235bb982dd52d0150a683ec6b9d7618fe79d1caa61e02e0a055bc80a9cc3\n",
            "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
            "Successfully built seqeval\n",
            "Installing collected packages: seqeval\n",
            "Successfully installed seqeval-1.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tokenizers"
      ],
      "metadata": {
        "id": "5Odj4Jg7XKEO",
        "outputId": "5ad686f2-b7b3-4049-a13b-639cde184101",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tokenizers\n",
            "  Downloading tokenizers-0.11.6-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5 MB 6.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: tokenizers\n",
            "Successfully installed tokenizers-0.11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers"
      ],
      "metadata": {
        "id": "tj7f1PABWx2F",
        "outputId": "9580cdb9-5646-4fde-9de5-2de7d93a8c1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.17.0-py3-none-any.whl (3.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 7.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tokenizers!=0.11.3,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.11.6)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.63.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.4.0-py3-none-any.whl (67 kB)\n",
            "\u001b[K     |████████████████████████████████| 67 kB 6.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.49-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.6.0)\n",
            "Collecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 67.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.7.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: pyyaml, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.4.0 pyyaml-6.0 sacremoses-0.0.49 transformers-4.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3CdzqLFpADv"
      },
      "source": [
        "## 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dBPvqzqpG_w",
        "outputId": "a67a5579-1baa-4fab-870e-a6b7fd83618e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12600\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "root = '/content/drive/MyDrive/news_class9x1400/'\n",
        "categories = os.listdir(root)\n",
        "\n",
        "dataset = []\n",
        "\n",
        "for cat in categories:\n",
        "  files = os.listdir(root + cat)\n",
        "  for i, f in enumerate(files):\n",
        "    fname = root + cat + '/' + f\n",
        "    file = open(fname, 'r', encoding='utf-8')\n",
        "    strings = file.read()\n",
        "    dataset.append([strings])\n",
        "    file.close()\n",
        "\n",
        "print(len(dataset))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random.shuffle(dataset)\n",
        "mini_dataset = dataset[:800]"
      ],
      "metadata": {
        "id": "k6zv1WC7WLWG"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMI63w5l_099",
        "outputId": "a1073bcd-5a11-4aa3-d207-5909ebf7f967"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['정세균 유명환 장관 욕설, 기절초풍할 상황\\n민주당이 지난 22일 외통위에서 천정배 의원을 가리키며 미친X 욕설을 한 유명환 외교통상부장관의 경질을 요구하고 나섰다.\\n정세균 대표는 29일 오전 국회 본관 246호에서 열린 의원총회 모두발언을 통해 속된 말로 기절초풍할 상황이 대한민국 국회에서 벌어졌다며 국회 경시하는 풍조가 벌써 몇 번째냐, 총리부터 시작해서 문화부 장관, 기획재정부 장관, 거기에 외교부 장관까지 가세를 하는 형국이 됐다고 비판했다.\\n정 대표는 또 사적인 술자리에서 그런 얘기를 해도 용납될 수 없는 일인데, 국회에 장관이 나와서 국무위원석에 앉아서 야당 중진의원에게 그런 얘기를 했다는 것이 기가 막힐 노릇이라며 절대 용납해서는 안 된다고 목소리를 높였다.\\n이어 그는 한승수 총리가 공개적으로 사과하고 유명환 외교부 장관은 스스로 사퇴해야 한다며 만약 사퇴하지 않으면 대통령이 경질해야 한다고 주장했다.\\n아울러 정 대표는 각 상임위에서 정부 각료들의 버릇을 뜯어고쳐야 한다며 민주당 의원들에게 강력한 대응을 요청했다.\\n그는 입법부는 국민의 대표가 나와서 국민을 대신해서 일을 하고 있는 것인데, 장관들이 어떻게 이런 짓을 할 수 있느냐면서 이 부분에 대해서 확실하게 노력해 주시기 바란다고 말했다.\\n노영민 대변인도 공식 브리핑을 통해 유명환 장관을 강력히 비난했다.\\n노 대변인은 유 장관을 향해 국무위원의 발언이라고는 생각하기 어려운 시정잡배 같은 막말이라고 비판한 뒤 국회를 없애야 한다는 위험천만한 발언을 국민이 어떻게 받아들일지 걱정이라고 지적했다.\\n노 대변인은 또 도대체 이 정부 국무위원들의 수준이 왜 이런지 모르겠다면서 유유상종이라는 말도 있고, 윗물이 맑아야 아랫물이 맑다는 얘기도 있다, 이명박 대통령은 제발 주변 좀 돌아보시기 바란다고 성토했다.\\n박병석 정책위원장도 이날 오전 <불교방송> 김재원의 아침저널에 출연해 유 장관의 발언에 대해 분노와 자괴감이 든다면서 한나라당이 청와대의 지시와 방침에 맹종하기 때문에 이런 경시 문제가 생겼다고 비판했다.\\n한편 한나라당은 유 장관 발언에 대해 어떤 논평도 내놓지 않았다.\\n다만 홍준표 원내대표가 28일 기자간담회에서 속으로만 생각하지\\n뭐하려고 밖으로 (말을) 했는지 모르겠다고 짤막하게 언급했을 뿐이다.']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "mini_dataset[241]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LAMmcAbI__hf"
      },
      "source": [
        "## 데이터 전처리"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "table = str.maketrans({\n",
        "    '\\'': '',\n",
        "    '\\\"': '',\n",
        "    '★': '',\n",
        "    '▲': '',\n",
        "    '┌': '',\n",
        "    '├': '',\n",
        "    '│': '',\n",
        "    '└': '',\n",
        "    '→': ''\n",
        "\n",
        "})\n",
        "test = '\"안녕\"하세★요? 좋은 아▲침입┌니├다. 오│늘도 힘내└세요→!'\n",
        "test = test.translate(table)\n",
        "\n",
        "test"
      ],
      "metadata": {
        "id": "qdHAtAEy5VSa",
        "outputId": "a343b8ec-2084-4efc-ed5a-8a6339670c68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요? 좋은 아침입니다. 오늘도 힘내세요!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqZ4DX-5_3zR"
      },
      "outputs": [],
      "source": [
        "import kss\n",
        "import random\n",
        "\n",
        "process_dataset = []\n",
        "\n",
        "for sentences in mini_dataset:\n",
        "  sentences = sentences[0]\n",
        "  sentences = sentences.translate(table)\n",
        "  sentences = sentences.split(\"\\n\")\n",
        "\n",
        "  for sentence in sentences:\n",
        "    process_dataset.extend(kss.split_sentences(sentence))\n",
        "\n",
        "\n",
        "len(process_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 4h 36m \n",
        "\n",
        "len(process_dataset)"
      ],
      "metadata": {
        "id": "sXmDsOkbuiNI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test = train_test_split(process_dataset, test_size = 0.2, random_state  = 42)\n",
        "train, val = train_test_split(train, test_size = 0.2, random_state = 42)\n",
        "\n",
        "print(len(train), len(val), len(test))"
      ],
      "metadata": {
        "id": "JlF-pc7d74NP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_datafile(file_name, dataset):\n",
        "  with open(\n",
        "      os.path.join(root, file_name), mode = 'w', encoding='utf-8'\n",
        "  ) as f:\n",
        "    for data in dataset:\n",
        "      f.write(data)\n",
        "\n",
        "save_datafile('train.txt', train)\n",
        "save_datafile('val.txt', val)\n",
        "save_datafile('test.txt', test)\n",
        "\n",
        "print('train, val, test dataset 저장 완료!')"
      ],
      "metadata": {
        "id": "4bbdLiBV76nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 띄어쓰기를 위한 클래스"
      ],
      "metadata": {
        "id": "PpWPjR0wTS7O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import List\n",
        "\n",
        "def load_slot_labels() -> List[str]:\n",
        "    \"\"\"tag label 종류 리턴\"\"\"\n",
        "    return [\"UNK\", \"PAD\", \"O\", \"B\", \"I\", \"E\", \"S\"]"
      ],
      "metadata": {
        "id": "yiZbUrjboyja"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Callable, List, Tuple\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "class CorpusDataset(Dataset):\n",
        "  def __init__(self, data_path: str, transform: Callable[[List, List], Tuple]):\n",
        "    self.sentences = []\n",
        "    self.slot_labels = ['UNK', 'PAD', 'B', 'I']\n",
        "    self._load_data(data_path)\n",
        "    self.transform = transform\n",
        "\n",
        "  def _load_data(self, data_path: str):\n",
        "    with open(data_path, mode = 'r', encoding = 'utf-8') as f:\n",
        "      lines = f.readlines()\n",
        "      self.sentences = [line.split() for line in lines]\n",
        "\n",
        "  def _get_tags(self, sentences: List[str]) -> List[str]:\n",
        "    tags = []\n",
        "    for word in sentence:\n",
        "      for i in range(len(word)):\n",
        "        if i == 0:\n",
        "            tags.append(\"B\")\n",
        "        else:\n",
        "            tags.append(\"I\")\n",
        "    return tags\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.sentences)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    sentence = \"\".join(self.sentences[idx])\n",
        "    sentence = [s for s in sentence]\n",
        "    tags = self._get_tags(self.sentences[idx])\n",
        "    tags = [self.slot_labels.index(t) for t in tags]\n",
        "\n",
        "    (\n",
        "        input_ids,\n",
        "        attention_mask,\n",
        "        token_type_ids,\n",
        "        slot_label_ids, \n",
        "    ) = self.transform(sentence, tags)\n",
        "\n",
        "    return input_ids, attention_mask, token_type_ids, slot_label_ids"
      ],
      "metadata": {
        "id": "LqZH3YA0nRA0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenization_kobert\n"
      ],
      "metadata": {
        "id": "cRz2dZChaYF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coding=utf-8\n",
        "# Copyright 2018 Google AI, Google Brain and Carnegie Mellon University Authors and the HuggingFace Inc. team and Jangwon Park\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\"\"\" Tokenization classes for KoBERT model \"\"\"\n",
        "\n",
        "\n",
        "import logging\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        "import sentencepiece as spm\n",
        "\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "VOCAB_FILES_NAMES = {\n",
        "    \"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "    \"vocab_txt\": \"vocab.txt\",\n",
        "}\n",
        "\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\",\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\",\n",
        "    },\n",
        "}\n",
        "\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512,\n",
        "    \"monologg/kobert-lm\": 512,\n",
        "    \"monologg/distilkobert\": 512,\n",
        "}\n",
        "\n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False},\n",
        "}\n",
        "\n",
        "SPIECE_UNDERLINE = \"▁\"\n",
        "\n",
        "\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "    SentencePiece based tokenizer. Peculiarities:\n",
        "        - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        vocab_file,\n",
        "        vocab_txt,\n",
        "        do_lower_case=False,\n",
        "        remove_space=True,\n",
        "        keep_accents=False,\n",
        "        unk_token=\"[UNK]\",\n",
        "        sep_token=\"[SEP]\",\n",
        "        pad_token=\"[PAD]\",\n",
        "        cls_token=\"[CLS]\",\n",
        "        mask_token=\"[MASK]\",\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, \"r\", encoding=\"utf-8\") as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        "\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\n",
        "                \"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                \"pip install sentencepiece\"\n",
        "            )\n",
        "\n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.token2idx, **self.added_tokens_encoder)\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\n",
        "                \"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                \"pip install sentencepiece\"\n",
        "            )\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        "\n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        "\n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize(\"NFKD\", outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _tokenize(self, text):\n",
        "        \"\"\"Tokenize a string.\"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        "        pieces = self.sp_model.encode(text, out_type=str)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        "\n",
        "        return new_pieces\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        "\n",
        "    def _convert_id_to_token(self, index):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A KoBERT sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(\n",
        "                map(\n",
        "                    lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0,\n",
        "                    token_ids_0,\n",
        "                )\n",
        "            )\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A KoBERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\"Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "        to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        "\n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        "\n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "\n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "metadata": {
        "id": "lOZ4_GDDacSQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "class Preprocessor:\n",
        "    def __init__(self, max_len: int):\n",
        "        self.tokenizer = KoBertTokenizer.from_pretrained(\"monologg/kobert\")\n",
        "        self.max_len = max_len\n",
        "        self.pad_token_id = 0\n",
        "\n",
        "    def get_input_features(\n",
        "        self, sentence: List[str], tags: List[str]\n",
        "    ) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:\n",
        "        \"\"\"문장과 띄어쓰기 tagging에 대해 feature로 변환한다.\n",
        "\n",
        "        Args:\n",
        "            sentence: 문장\n",
        "            tags: 띄어쓰기 tagging\n",
        "\n",
        "        Returns:\n",
        "            feature를 리턴한다.\n",
        "            input_ids, attention_mask, token_type_ids, slot_labels\n",
        "        \"\"\"\n",
        "\n",
        "        input_tokens = []\n",
        "        slot_label_ids = []\n",
        "\t\t\t\t\t\n",
        "        # tokenize\n",
        "        for word, tag in zip(sentence, tags):\n",
        "            tokens = self.tokenizer.tokenize(word)\n",
        "\n",
        "            if len(tokens) == 0:\n",
        "                tokens = self.tokenizer.unk_token\n",
        "\n",
        "            input_tokens.extend(tokens)\n",
        "\n",
        "            for i in range(len(tokens)):\n",
        "                if i == 0:\n",
        "                    slot_label_ids.extend([tag])\n",
        "                else:\n",
        "                    slot_label_ids.extend([self.pad_token_id])\n",
        "\n",
        "        # max_len보다 길이가 길면 뒤에 자르기\n",
        "        if len(input_tokens) > self.max_len - 2:\n",
        "            input_tokens = input_tokens[: self.max_len - 2]\n",
        "            slot_label_ids = slot_label_ids[: self.max_len - 2]\n",
        "\n",
        "        # cls, sep 추가\n",
        "        input_tokens = (\n",
        "            [self.tokenizer.cls_token] + input_tokens + [self.tokenizer.sep_token]\n",
        "        )\n",
        "        slot_label_ids = [self.pad_token_id] + slot_label_ids + [self.pad_token_id]\n",
        "\n",
        "        # token을 id로 변환\n",
        "        input_ids = self.tokenizer.convert_tokens_to_ids(input_tokens)\n",
        "\n",
        "        attention_mask = [1] * len(input_ids)\n",
        "        token_type_ids = [0] * len(input_ids)\n",
        "\n",
        "        # padding\n",
        "        pad_len = self.max_len - len(input_tokens)\n",
        "        input_ids = input_ids + ([self.tokenizer.pad_token_id] * pad_len)\n",
        "        slot_label_ids = slot_label_ids + ([self.pad_token_id] * pad_len)\n",
        "        attention_mask = attention_mask + ([0] * pad_len)\n",
        "        token_type_ids = token_type_ids + ([0] * pad_len)\n",
        "\n",
        "        input_ids = torch.tensor(input_ids, dtype=torch.long)\n",
        "        attention_mask = torch.tensor(attention_mask, dtype=torch.long)\n",
        "        token_type_ids = torch.tensor(token_type_ids, dtype=torch.long)\n",
        "        slot_label_ids = torch.tensor(slot_label_ids, dtype=torch.long)\n",
        "\n",
        "        return input_ids, attention_mask, token_type_ids, slot_label_ids"
      ],
      "metadata": {
        "id": "JYLjOPIlTLit"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from omegaconf import OmegaConf\n",
        "\n",
        "config = OmegaConf.load('/content/drive/MyDrive/train_config.yaml')"
      ],
      "metadata": {
        "id": "xes-65_6qLMf"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = Preprocessor(config.max_len)\n",
        "dataset = CorpusDataset(data_path, preprocessor.get_input_features)"
      ],
      "metadata": {
        "id": "pYVtHNZXZWyy",
        "outputId": "115918aa-ccbc-410f-c195-bae3f53ae25b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'BertTokenizer'. \n",
            "The class this function is called from is 'KoBertTokenizer'.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-43-6d3c38b5aa82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPreprocessor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_len\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCorpusDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_input_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data_path' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 생성"
      ],
      "metadata": {
        "id": "uE41yxbCazAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import pytorch_lightning as pl\n",
        "from transformers import BertConfig, BertModel, AdamW\n",
        "from torch.utils.data import DataLoader\n",
        "from seqeval.metrics import f1_score\n",
        "\n",
        "\n",
        "class SpacingBertModel(pl.LightningModule):\n",
        "    def __init__(\n",
        "        self,\n",
        "        config,\n",
        "        dataset: CorpusDataset,\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.config = config\n",
        "        self.dataset = dataset\n",
        "        self.slot_labels_type = [\"UNK\", \"PAD\", \"B\", \"I\"]\n",
        "        self.pad_token_id = 0\n",
        "\n",
        "        self.bert_config = BertConfig.from_pretrained(\n",
        "            self.config.bert_model, num_labels=len(self.slot_labels_type)\n",
        "        )\n",
        "        self.model = BertModel.from_pretrained(\n",
        "            self.config.bert_model, config=self.bert_config\n",
        "        )\n",
        "        self.dropout = nn.Dropout(self.config.dropout_rate)\n",
        "        self.linear = nn.Linear(\n",
        "            self.bert_config.hidden_size, len(self.slot_labels_type)\n",
        "        )\n",
        "\n",
        "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
        "        outputs = self.model(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        x = outputs[0]\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def training_step(self, batch, batch_nb):\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        loss = self._calculate_loss(outputs, slot_labels)\n",
        "        tensorboard_logs = {\"train_loss\": loss}\n",
        "\n",
        "        return {\"loss\": loss, \"log\": tensorboard_logs}\n",
        "\n",
        "    def validation_step(self, batch, batch_nb):\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        loss = self._calculate_loss(outputs, slot_label_ids)\n",
        "        pred_slot_labels, gt_slot_labels = self._convert_ids_to_labels(\n",
        "            outputs, slot_label_ids\n",
        "        )\n",
        "\n",
        "        val_f1 = self._f1_score(gt_slot_labels, pred_slot_labels)\n",
        "\n",
        "        return {\"val_loss\": loss, \"val_f1\": val_f1}\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        val_loss = torch.stack([x[\"val_loss\"] for x in outputs]).mean()\n",
        "        val_f1 = torch.stack([x[\"val_f1\"] for x in outputs]).mean()\n",
        "\n",
        "        tensorboard_log = {\n",
        "            \"val_loss\": val_loss,\n",
        "            \"val_f1\": val_f1,\n",
        "        }\n",
        "\n",
        "        return {\"val_loss\": val_loss, \"progress_bar\": tensorboard_log}\n",
        "\n",
        "    def test_step(self, batch, batch_nb):\n",
        "\n",
        "        input_ids, attention_mask, token_type_ids, slot_label_ids = batch\n",
        "\n",
        "        outputs = self(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids,\n",
        "        )\n",
        "\n",
        "        pred_slot_labels, gt_slot_labels = self._convert_ids_to_labels(\n",
        "            outputs, slot_label_ids\n",
        "        )\n",
        "\n",
        "        test_f1 = self._f1_score(gt_slot_labels, pred_slot_labels)\n",
        "\n",
        "        test_step_outputs = {\n",
        "            \"test_f1\": test_f1,\n",
        "        }\n",
        "\n",
        "        return test_step_outputs\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        test_f1 = torch.stack([x[\"test_f1\"] for x in outputs]).mean()\n",
        "\n",
        "        test_step_outputs = {\n",
        "            \"test_f1\": test_f1,\n",
        "        }\n",
        "\n",
        "        return test_step_outputs\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return AdamW(self.model.parameters(), lr=2e-5, eps=1e-8)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(self.dataset[\"train\"], batch_size=self.config.train_batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(self.dataset[\"val\"], batch_size=self.config.eval_batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(self.dataset[\"test\"], batch_size=self.config.eval_batch_size)\n",
        "\n",
        "    def _calculate_loss(self, outputs, labels):\n",
        "        active_logits = outputs.view(-1, len(self.slot_labels_type))\n",
        "        active_labels = labels.view(-1)\n",
        "        loss = F.cross_entropy(active_logits, active_labels)\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def _f1_score(self, gt_slot_labels, pred_slot_labels):\n",
        "        return torch.tensor(\n",
        "            f1_score(gt_slot_labels, pred_slot_labels), dtype=torch.float32\n",
        "        )\n",
        "\n",
        "    def _convert_ids_to_labels(self, outputs, slot_labels):\n",
        "        _, y_hat = torch.max(outputs, dim=2)\n",
        "        y_hat = y_hat.detach().cpu().numpy()\n",
        "        slot_label_ids = slot_labels.detach().cpu().numpy()\n",
        "\n",
        "        slot_label_map = {i: label for i, label in enumerate(self.slot_labels_type)}\n",
        "        slot_gt_labels = [[] for _ in range(slot_label_ids.shape[0])]\n",
        "        slot_pred_labels = [[] for _ in range(slot_label_ids.shape[0])]\n",
        "\n",
        "        for i in range(slot_label_ids.shape[0]):\n",
        "            for j in range(slot_label_ids.shape[1]):\n",
        "                if slot_label_ids[i, j] != self.pad_token_id:\n",
        "                    slot_gt_labels[i].append(slot_label_map[slot_label_ids[i][j]])\n",
        "                    slot_pred_labels[i].append(slot_label_map[y_hat[i][j]])\n",
        "\n",
        "        return slot_pred_labels, slot_gt_labels"
      ],
      "metadata": {
        "id": "-N8IkQtea0av"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ],
      "metadata": {
        "id": "yJEtlPbjpXL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = '/content/drive/MyDrive/train_test/train.txt'\n",
        "test_data_path = '/content/drive/MyDrive/train_test/test.txt'\n",
        "val_data_path = '/content/drive/MyDrive/train_test/val.txt'"
      ],
      "metadata": {
        "id": "XRqdvLG4pefs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = {}\n",
        "dataset[\"train\"] = CorpusDataset(\n",
        "    train_data_path, Preprocessor.get_input_features\n",
        ")\n",
        "dataset[\"val\"] = CorpusDataset(\n",
        "    val_data_path, Preprocessor.get_input_features\n",
        ")\n",
        "dataset[\"test\"] = CorpusDataset(\n",
        "    test_data_path, Preprocessor.get_input_features\n",
        ")\n",
        "\n",
        "\n",
        "bert_finetuner = SpacingBertModel(config, dataset)"
      ],
      "metadata": {
        "id": "vwE5rSYGpYfd",
        "outputId": "c142757e-42da-4442-dc01-8be509e13381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1d3244f783f7421db00b9ce5bad36b47",
            "dc47201a0d2147be96fa819c719044ad",
            "4b366baff6784490a92fffa68152aaa3",
            "54cf3df4b0b6446b8871b65a84b57314",
            "b48bfd34cae24798a1047bff2ece247c",
            "2604fc38208f419fae8133a0b4a91253",
            "86f4821b92b347f6b3f94543ef3d0ff0",
            "122f6e6557fa433a8f4dfb5b14766b5b",
            "31d9a4af9ab14deea6c14fe6cb277b10",
            "317476466e994f7b82827f2593bac889",
            "f6f0161593d44a7ea4d68a1e9ff08f3f"
          ]
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading:   0%|          | 0.00/352M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d3244f783f7421db00b9ce5bad36b47"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "logger = TensorBoardLogger(\n",
        "    save_dir=os.path.join(config.log_path, config.task), version=1, name=config.task\n",
        ")\n",
        "\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=\"checkpoints/\"+ config.task + \"/{epoch}_{val_loss:35f}\",\n",
        "    verbose=True,\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_top_k=3,\n",
        "    prefix=\"\",\n",
        ")\n",
        "\n",
        "early_stop_callback = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    min_delta=0.0001,\n",
        "    patience=3,\n",
        "    verbose=False,\n",
        "    mode=\"min\",\n",
        ")"
      ],
      "metadata": {
        "id": "UaMdwERtqb0Q"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_devices = torch.cuda.device_count()\n",
        "print(n_devices)\n",
        "\n",
        "for i in range(n_devices):\n",
        "    print(torch.cuda.get_device_name(i))"
      ],
      "metadata": {
        "id": "B6SDNZyiDu7z",
        "outputId": "e08da57c-59db-4a45-a969-f7ed8354980a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n",
            "Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# GPU 설정\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "id": "UuZj-hVbEo8a"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = pl.Trainer(gpus=1)\n",
        "\n",
        "trainer.fit(bert_finetuner)\n",
        "trainer.test()"
      ],
      "metadata": {
        "id": "OAw-88c_q_Dn",
        "outputId": "dceda3f3-18a0-42fa-eb83-c1f1c01d88de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 757,
          "referenced_widgets": [
            "cdf7fe6351094a198da29ff04decd948",
            "880d1bf0eaa840fe8da7f504f6cf46f8",
            "00b3de0258e74fa88baac4e013c83513",
            "ee00902970254e2fb876916a5e41a07a",
            "75ae59ccc7ad4518bc54700d333f7a76",
            "e9a03362f72f4004a34a323de0a4cfe9",
            "ca3191c62ca94cf7b20a8898ec1adfa2",
            "2eba3bbc32054ed49a07580cd33ad576",
            "c24fbd4c72c84cc2b3c5be2b518c7758",
            "5f677a47f7454b1ab6083e92ab3e0c43",
            "f194d481f917481da9551a187dbc5530"
          ]
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: False, using: 0 TPU cores\n",
            "IPU available: False, using: 0 IPUs\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "Missing logger folder: /content/lightning_logs\n",
            "\n",
            "  | Name    | Type      | Params\n",
            "--------------------------------------\n",
            "0 | model   | BertModel | 92.2 M\n",
            "1 | dropout | Dropout   | 0     \n",
            "2 | linear  | Linear    | 3.1 K \n",
            "--------------------------------------\n",
            "92.2 M    Trainable params\n",
            "0         Non-trainable params\n",
            "92.2 M    Total params\n",
            "368.760   Total estimated model params size (MB)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Validation sanity check: 0it [00:00, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cdf7fe6351094a198da29ff04decd948"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-77c4fe61dc50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbert_finetuner\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, train_dataloader, ckpt_path)\u001b[0m\n\u001b[1;32m    739\u001b[0m             \u001b[0mtrain_dataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    740\u001b[0m         self._call_and_handle_interrupt(\n\u001b[0;32m--> 741\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_impl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatamodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    742\u001b[0m         )\n\u001b[1;32m    743\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(self, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    683\u001b[0m         \"\"\"\n\u001b[1;32m    684\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mtrainer_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m         \u001b[0;31m# TODO: treat KeyboardInterrupt as BaseException (delete the code below) in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;31m# TODO: ckpt_path only in v1.7\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m         \u001b[0mckpt_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpt_path\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mckpt_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mckpt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m         \u001b[0;31m# dispatch `start_training` or `start_evaluating` or `start_predicting`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1199\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1201\u001b[0m         \u001b[0;31m# plugin will finalized fitting (e.g. ddp_spawn will load trained model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1277\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_predicting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1279\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mstart_training\u001b[0;34m(self, trainer)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m         \u001b[0;31m# double dispatch to initiate the training loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 202\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_stage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstart_evaluating\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"pl.Trainer\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mrun_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredicting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1289\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1290\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_pre_training_routine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1309\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogress_bar_callback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1311\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_sanity_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m         \u001b[0;31m# enable train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36m_run_sanity_check\u001b[0;34m(self, ref_model)\u001b[0m\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1370\u001b[0m             \u001b[0;31m# reload dataloaders\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1371\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_evaluation_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reload_evaluation_dataloaders\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1373\u001b[0m             \u001b[0;31m# run eval step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py\u001b[0m in \u001b[0;36m_reload_evaluation_dataloaders\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_test_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mval_dataloaders\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_reload_val_dl\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_val_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_on_evaluation_start\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py\u001b[0m in \u001b[0;36mreset_val_dataloader\u001b[0;34m(self, model)\u001b[0m\n\u001b[1;32m    550\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_defined\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m             self.num_val_batches, self.val_dataloaders = self._reset_eval_dataloader(\n\u001b[0;32m--> 552\u001b[0;31m                 \u001b[0mRunningStage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVALIDATING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpl_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m             )\n\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py\u001b[0m in \u001b[0;36m_reset_eval_dataloader\u001b[0;34m(self, mode, model)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;31m# always get the loaders first so we can count how many there are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m         \u001b[0mdataloaders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/data_loading.py\u001b[0m in \u001b[0;36mrequest_dataloader\u001b[0;34m(self, stage, model)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"{stage.dataloader_prefix}_dataloader\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"on_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m             \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/connectors/data_connector.py\u001b[0m in \u001b[0;36mdataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpl_module\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLightningDataModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mcall_hook\u001b[0;34m(self, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0mmodel_fx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpl_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_fx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_fx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m             \u001b[0;31m# *Bad code alert*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-b80142eb0971>\u001b[0m in \u001b[0;36mval_dataloader\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtest_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val'"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "CP2_KoSpacing.ipynb",
      "provenance": [],
      "mount_file_id": "1GOzxSVo7c6s_VIL1IPiy2rgupLE9ZRqc",
      "authorship_tag": "ABX9TyPYubFa3B9ByfKt7T2em6Ke",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1d3244f783f7421db00b9ce5bad36b47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dc47201a0d2147be96fa819c719044ad",
              "IPY_MODEL_4b366baff6784490a92fffa68152aaa3",
              "IPY_MODEL_54cf3df4b0b6446b8871b65a84b57314"
            ],
            "layout": "IPY_MODEL_b48bfd34cae24798a1047bff2ece247c"
          }
        },
        "dc47201a0d2147be96fa819c719044ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2604fc38208f419fae8133a0b4a91253",
            "placeholder": "​",
            "style": "IPY_MODEL_86f4821b92b347f6b3f94543ef3d0ff0",
            "value": "Downloading: 100%"
          }
        },
        "4b366baff6784490a92fffa68152aaa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_122f6e6557fa433a8f4dfb5b14766b5b",
            "max": 368792146,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31d9a4af9ab14deea6c14fe6cb277b10",
            "value": 368792146
          }
        },
        "54cf3df4b0b6446b8871b65a84b57314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_317476466e994f7b82827f2593bac889",
            "placeholder": "​",
            "style": "IPY_MODEL_f6f0161593d44a7ea4d68a1e9ff08f3f",
            "value": " 352M/352M [00:06&lt;00:00, 56.3MB/s]"
          }
        },
        "b48bfd34cae24798a1047bff2ece247c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2604fc38208f419fae8133a0b4a91253": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86f4821b92b347f6b3f94543ef3d0ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "122f6e6557fa433a8f4dfb5b14766b5b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31d9a4af9ab14deea6c14fe6cb277b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "317476466e994f7b82827f2593bac889": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f0161593d44a7ea4d68a1e9ff08f3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cdf7fe6351094a198da29ff04decd948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_880d1bf0eaa840fe8da7f504f6cf46f8",
              "IPY_MODEL_00b3de0258e74fa88baac4e013c83513",
              "IPY_MODEL_ee00902970254e2fb876916a5e41a07a"
            ],
            "layout": "IPY_MODEL_75ae59ccc7ad4518bc54700d333f7a76"
          }
        },
        "880d1bf0eaa840fe8da7f504f6cf46f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9a03362f72f4004a34a323de0a4cfe9",
            "placeholder": "​",
            "style": "IPY_MODEL_ca3191c62ca94cf7b20a8898ec1adfa2",
            "value": "Validation sanity check: "
          }
        },
        "00b3de0258e74fa88baac4e013c83513": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "info",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2eba3bbc32054ed49a07580cd33ad576",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c24fbd4c72c84cc2b3c5be2b518c7758",
            "value": 0
          }
        },
        "ee00902970254e2fb876916a5e41a07a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f677a47f7454b1ab6083e92ab3e0c43",
            "placeholder": "​",
            "style": "IPY_MODEL_f194d481f917481da9551a187dbc5530",
            "value": " 0/? [00:00&lt;?, ?it/s]"
          }
        },
        "75ae59ccc7ad4518bc54700d333f7a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "inline-flex",
            "flex": null,
            "flex_flow": "row wrap",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "100%"
          }
        },
        "e9a03362f72f4004a34a323de0a4cfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca3191c62ca94cf7b20a8898ec1adfa2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2eba3bbc32054ed49a07580cd33ad576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": "2",
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c24fbd4c72c84cc2b3c5be2b518c7758": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5f677a47f7454b1ab6083e92ab3e0c43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f194d481f917481da9551a187dbc5530": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}